<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>WebSocket Audio Recorder</title>
    <style>
      :root {
        font-family: system-ui, Avenir, Helvetica, Arial, sans-serif;
        line-height: 1.5;
        font-weight: 400;

        color-scheme: light dark;
        color: rgba(255, 255, 255, 0.87);
        background-color: #242424;

        font-synthesis: none;
        text-rendering: optimizeLegibility;
        -webkit-font-smoothing: antialiased;
        -moz-osx-font-smoothing: grayscale;
      }

      body {
        font-family: Arial, sans-serif;
        max-width: 800px;
        margin: 0 auto;
        padding: 20px;
      }

      .container {
        background: #f5f5f5;
        padding: 20px;
        border-radius: 10px;
        margin: 20px 0;
      }

      .control-group {
        margin: 15px 0;
      }

      label {
        display: block;
        margin-bottom: 5px;
        font-weight: bold;
      }

      select,
      button {
        padding: 10px 15px;
        font-size: 16px;
        border: 2px solid #ddd;
        border-radius: 5px;
      }

      select {
        width: 100%;
        max-width: 400px;
      }

      button {
        background: #007bff;
        color: white;
        border: 2px solid #007bff;
        cursor: pointer;
        margin: 5px;
      }

      button:hover {
        background: #0056b3;
        border-color: #0056b3;
      }

      button:disabled {
        background: #6c757d;
        border-color: #6c757d;
        cursor: not-allowed;
      }

      .recording {
        background: #dc3545 !important;
        border-color: #dc3545 !important;
      }

      .recording:hover {
        background: #c82333 !important;
        border-color: #c82333 !important;
      }

      #status {
        padding: 10px;
        margin: 10px 0;
        border-radius: 5px;
        font-weight: bold;
      }

      .status-connected {
        background: #d4edda;
        color: #155724;
        border: 1px solid #c3e6cb;
      }

      .status-recording {
        background: #f8d7da;
        color: #721c24;
        border: 1px solid #f5c6cb;
      }

      .status-error {
        background: #f8d7da;
        color: #721c24;
        border: 1px solid #f5c6cb;
      }
    </style>
  </head>
  <body>
    <h1>WebSocket Audio Recorder</h1>

    <div class="container">
      <div class="control-group">
        <label for="deviceSelect">Select Audio Device:</label>
        <select id="deviceSelect">
          <option value="">Loading devices...</option>
        </select>
      </div>

      <div class="control-group">
        <button id="recordButton" disabled>Start Recording</button>
        <button id="testButton" disabled>Test Microphone</button>
      </div>

      <div id="status">Connecting to server...</div>
    </div>

    <script type="module">
      import { MicVAD, utils } from "@ricky0123/vad-web";

      const CONTROL_MESSAGES = {
        RECORD_START: 0x01,
        RECORD_END: 0x02,
        USER_SPEAKING: 0x03,
        USER_PAUSED: 0x04,
      };

      class AudioRecorder {
        constructor() {
          this.websocket = null;
          this.audioContext = null;
          this.audioWorkletNode = null;
          this.source = null;
          this.stream = null;
          this.recording = false;
          this.devices = [];
          this.vad = null;
          this.isSpeaking = false;
          this.vadAudioBuffer = [];

          this.recordButton = document.getElementById("recordButton");
          this.testButton = document.getElementById("testButton");
          this.deviceSelect = document.getElementById("deviceSelect");
          this.statusDiv = document.getElementById("status");

          this.init();
        }

        async init() {
          try {
            await this.loadDevices();
            await this.initializeAudioContext();
            await this.initializeVAD();
            this.setupWebSocket();
            this.setupEventListeners();
          } catch (error) {
            this.updateStatus("Error initializing: " + error.message, "error");
          }
        }

        async initializeVAD() {
          try {
            this.vad = await MicVAD.new({
              onSpeechStart: () => {
                console.log("Speech started");
                if (this.recording && !this.isSpeaking) {
                  this.isSpeaking = true;
                  this.sendControlMessage(CONTROL_MESSAGES.USER_SPEAKING);
                  this.updateStatus(
                    "Recording - User speaking...",
                    "recording"
                  );
                }
              },
              onSpeechEnd: () => {
                console.log("Speech ended");
                if (this.recording && this.isSpeaking) {
                  this.isSpeaking = false;
                  this.sendControlMessage(CONTROL_MESSAGES.USER_PAUSED);
                  this.updateStatus("Recording - User paused...", "recording");
                }
              },
              onVADMisfire: () => {
                console.log("VAD misfire");
              },
              baseAssetPath: "/",
              onnxWASMBasePath: "/",
              model: "v5",
              // Let VAD manage its own stream independently
            });
            console.log("VAD initialized");
          } catch (error) {
            console.error("Error initializing VAD:", error);
            // Continue without VAD if it fails to load
            this.vad = null;
          }
        }

        async initializeAudioContext() {
          try {
            this.audioContext = new (window.AudioContext ||
              window.webkitAudioContext)({
              sampleRate: 48000, // Set desired sample rate
            });

            // Load the AudioWorklet processor
            await this.audioContext.audioWorklet.addModule(
              "./src/audio-processor.js"
            );

            this.updateStatus("Audio context initialized", "connected");
          } catch (error) {
            console.error("Error initializing AudioContext:", error);
            throw new Error(
              "Failed to initialize audio context: " + error.message
            );
          }
        }

        async loadDevices() {
          try {
            const devices = await navigator.mediaDevices.enumerateDevices();
            this.devices = devices.filter(
              (device) => device.kind === "audioinput"
            );

            this.deviceSelect.innerHTML = "";
            if (this.devices.length === 0) {
              this.deviceSelect.innerHTML =
                "<option>No audio devices found</option>";
              return;
            }

            this.devices.forEach((device) => {
              const option = document.createElement("option");
              option.value = device.deviceId;
              option.textContent =
                device.label || `Device ${device.deviceId.substr(0, 8)}`;
              this.deviceSelect.appendChild(option);
            });
          } catch (error) {
            console.error("Error loading devices:", error);
            this.deviceSelect.innerHTML =
              "<option>Error loading devices</option>";
          }
        }

        setupWebSocket() {
          this.websocket = new WebSocket("ws://localhost:4000");
          this.websocket.binaryType = "arraybuffer";

          this.websocket.onopen = () => {
            this.updateStatus("Connected to server", "connected");
            this.recordButton.disabled = false;
            this.testButton.disabled = false;
          };

          this.websocket.onmessage = (event) => {
            const message = JSON.parse(event.data);
            if (message.event === "recording-started") {
              this.updateStatus("Recording in progress...", "recording");
            } else if (message.event === "recording-saved") {
              this.updateStatus(
                `Recording saved as ${message.filename}`,
                "connected"
              );
            } else if (message.event === "error") {
              this.updateStatus("Server error: " + message.message, "error");
            }
          };

          this.websocket.onclose = () => {
            this.updateStatus("Disconnected from server", "error");
            this.recordButton.disabled = true;
            this.testButton.disabled = true;
          };

          this.websocket.onerror = (error) => {
            this.updateStatus("WebSocket error", "error");
            console.error("WebSocket error:", error);
          };
        }

        async getMediaStream() {
          const deviceId = this.deviceSelect.value;
          const constraints = {
            audio: deviceId ? { deviceId: { exact: deviceId } } : true,
            video: false,
          };

          return await navigator.mediaDevices.getUserMedia(constraints);
        }

        sendControlMessage(command) {
          const buffer = new ArrayBuffer(1);
          const view = new Uint8Array(buffer);

          view[0] = command;

          this.websocket.send(buffer);
        }

        async startRecording() {
          try {
            // Ensure clean state before starting
            await this.cleanupAudioResources();
            await this.resetVADState();

            // Resume audio context if suspended
            if (this.audioContext.state === "suspended") {
              await this.audioContext.resume();
            }

            // Verify audio context sample rate consistency
            console.log(
              `AudioContext sample rate: ${this.audioContext.sampleRate}Hz`
            );

            // Get fresh media stream for AudioWorklet
            this.stream = await this.getMediaStream();

            // Create media stream source
            this.source = this.audioContext.createMediaStreamSource(
              this.stream
            );

            // Create AudioWorklet node
            this.audioWorkletNode = new AudioWorkletNode(
              this.audioContext,
              "audio-processor"
            );

            // Set up message handling for audio data
            this.audioWorkletNode.port.onmessage = (event) => {
              if (event.data.type === "audioData" && this.recording) {
                // If VAD is available, only send audio when user is speaking
                if (this.vad) {
                  if (this.isSpeaking) {
                    // Send PCM data to WebSocket only when speaking
                    if (this.websocket.readyState === WebSocket.OPEN) {
                      this.websocket.send(event.data.data);
                    }
                  }
                  // VAD handles its own audio processing internally
                } else {
                  // If no VAD, send all audio data (fallback behavior)
                  if (this.websocket.readyState === WebSocket.OPEN) {
                    this.websocket.send(event.data.data);
                  }
                }
              }
            };

            // Connect the audio graph
            this.source.connect(this.audioWorkletNode);
            this.audioWorkletNode.connect(this.audioContext.destination);

            // Send sample rate to the processor
            this.audioWorkletNode.port.postMessage({
              type: "setSampleRate",
              sampleRate: this.audioContext.sampleRate,
            });

            // Send start recording event
            this.sendControlMessage(CONTROL_MESSAGES.RECORD_START);

            this.recording = true;

            // Start VAD if available (let it manage its own stream)
            if (this.vad) {
              try {
                await this.vad.start();
                console.log("VAD started with independent stream");
              } catch (vadError) {
                console.warn("Failed to start VAD:", vadError);
              }
            }

            this.recordButton.textContent = "Stop Recording";
            this.recordButton.classList.add("recording");
            this.testButton.disabled = true;
            this.deviceSelect.disabled = true;

            this.updateStatus(
              "Recording PCM audio with VAD - speak to begin...",
              "recording"
            );
          } catch (error) {
            this.updateStatus(
              "Error starting recording: " + error.message,
              "error"
            );
            console.error("Recording error:", error);
            // Ensure cleanup on error
            await this.cleanupAudioResources();
          }
        }

        async stopRecording() {
          if (this.recording) {
            this.recording = false;
            this.isSpeaking = false; // Reset speaking state

            // Stop VAD first
            if (this.vad) {
              try {
                this.vad.pause();
                console.log("VAD paused");
              } catch (vadError) {
                console.warn("Failed to pause VAD:", vadError);
              }
            }

            // Send stop recording event
            this.sendControlMessage(CONTROL_MESSAGES.RECORD_END);

            // Clean up audio resources
            await this.cleanupAudioResources();

            this.recordButton.textContent = "Start Recording";
            this.recordButton.classList.remove("recording");
            this.testButton.disabled = false;
            this.deviceSelect.disabled = false;

            this.updateStatus("Recording stopped", "connected");
          }
        }

        async cleanupAudioResources() {
          try {
            // Disconnect and cleanup audio nodes
            if (this.source) {
              this.source.disconnect();
              this.source = null;
              console.log("Audio source disconnected");
            }

            if (this.audioWorkletNode) {
              this.audioWorkletNode.disconnect();
              this.audioWorkletNode.port.onmessage = null; // Remove event listener
              this.audioWorkletNode = null;
              console.log("AudioWorklet node disconnected");
            }

            // Stop and cleanup media stream
            if (this.stream) {
              this.stream.getTracks().forEach((track) => {
                track.stop();
                console.log(`Stopped track: ${track.kind}`);
              });
              this.stream = null;
            }

            // Small delay to ensure cleanup completes
            await new Promise((resolve) => setTimeout(resolve, 100));
          } catch (error) {
            console.warn("Error during audio cleanup:", error);
          }
        }

        async resetVADState() {
          // Reset VAD internal state for fresh session
          if (this.vad) {
            try {
              // Pause VAD to reset its internal state
              if (this.vad.listening) {
                this.vad.pause();
              }

              // Reset our local VAD state
              this.isSpeaking = false;

              console.log("VAD state reset");
            } catch (error) {
              console.warn("Error resetting VAD state:", error);
            }
          }
        }

        //------------------

        setupEventListeners() {
          this.recordButton.addEventListener("click", async () => {
            if (this.recording) {
              await this.stopRecording();
            } else {
              await this.startRecording();
            }
          });

          this.testButton.addEventListener("click", () => {
            this.testMicrophone();
          });

          this.deviceSelect.addEventListener("change", async () => {
            if (this.recording) {
              alert("Cannot change device while recording");
              return;
            }
            // Clean up any existing streams when changing devices
            await this.cleanupAudioResources();
          });
        }

        async testMicrophone() {
          try {
            const stream = await this.getMediaStream();
            this.updateStatus("Microphone test - speak now...", "recording");

            setTimeout(() => {
              stream.getTracks().forEach((track) => track.stop());
              this.updateStatus("Microphone test completed", "connected");
            }, 3000);
          } catch (error) {
            this.updateStatus(
              "Microphone test failed: " + error.message,
              "error"
            );
          }
        }

        updateStatus(message, type = "") {
          this.statusDiv.textContent = message;
          this.statusDiv.className = type ? `status-${type}` : "";
        }
      }

      // Initialize the recorder when page loads
      document.addEventListener("DOMContentLoaded", () => {
        new AudioRecorder();
      });
    </script>
  </body>
</html>
